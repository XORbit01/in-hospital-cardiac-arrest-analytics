{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM_antC4JSpp"
      },
      "source": [
        "# IHCA Data Cleaning Workflow\n",
        "\n",
        "This notebook chronicles the end-to-end cleaning pipeline for the in-hospital cardiac arrest (IHCA) registry. The intent is to:\n",
        "\n",
        "- consolidate records captured in the `ND` and `ICU` source tabs\n",
        "- standardize clinical variables so downstream analytics receive consistent schemas\n",
        "- cross-check event timelines for internal consistency\n",
        "- derive interpretable features needed for survival and resuscitation analyses\n",
        "\n",
        "Each section states the clinical or data-quality motivation behind the transformations so that peers can audit, reproduce, or extend the workflow with confidence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoEKTTWUJSpr"
      },
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Install and import the core libraries required for the cleaning workflow. The dataset manipulation relies on `pandas` for structured ingests and vectorized transformations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1aoqqhvfFrU",
        "outputId": "4f0e0c19-d288-4d72-f992-0b9ec2b3d01e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezV3Qa0yJSps"
      },
      "source": [
        "### 2. Load Source Workbooks\n",
        "\n",
        "Read both source tabs (`ND` and `ICU`) from the master Excel file. Keeping them in separate DataFrames allows us to compare schemas and diagnose inconsistencies before merging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUYXj4L5gAAh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_nd = pd.read_excel(\"IHCA data 00.xlsx\", sheet_name=\"ND\")\n",
        "df_icu = pd.read_excel(\"IHCA data 00.xlsx\", sheet_name=\"ICU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZQUybUgJSps"
      },
      "source": [
        "### 3. Profile Raw Schemas\n",
        "\n",
        "Inspect column names, data types, and non-null counts for each sheet. Early profiling highlights naming drift and missingness patterns that must be reconciled before concatenating the sources.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRm71YqCgu7c",
        "outputId": "bf05390d-dbc0-4b30-b7bb-bf0d9a008971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 26 columns):\n",
            " #   Column                             Non-Null Count  Dtype         \n",
            "---  ------                             --------------  -----         \n",
            " 0   MRN                                200 non-null    int64         \n",
            " 1   Gend                               200 non-null    object        \n",
            " 2   Birth\n",
            "Year                         200 non-null    int64         \n",
            " 3   Arrest\n",
            "Year                        200 non-null    int64         \n",
            " 4   Age                                200 non-null    int64         \n",
            " 5   CAD                                200 non-null    object        \n",
            " 6   Heart\n",
            "failure                      200 non-null    object        \n",
            " 7   Heart \n",
            "disease                     200 non-null    object        \n",
            " 8   Hyper\n",
            "-tension                     200 non-null    object        \n",
            " 9   COPD                               200 non-null    object        \n",
            " 10  Diabetes                           200 non-null    object        \n",
            " 11  Cancer                             200 non-null    object        \n",
            " 12  Covid\n",
            "at adm                       200 non-null    object        \n",
            " 13  Smoking                            200 non-null    object        \n",
            " 14  Event \n",
            "loc.                        200 non-null    object        \n",
            " 15  Arrest\n",
            "date                        200 non-null    datetime64[ns]\n",
            " 16  Arrest\n",
            "time                        200 non-null    object        \n",
            " 17  CPR \n",
            "date                          200 non-null    datetime64[ns]\n",
            " 18  CPR \n",
            "time                          200 non-null    object        \n",
            " 19  Defibrillation \n",
            "(time, frequency)  200 non-null    object        \n",
            " 20  Initial \n",
            "cardiac \n",
            "rhythm           199 non-null    object        \n",
            " 21  ROSC \n",
            "(y/n)                        200 non-null    object        \n",
            " 22  ROSC \n",
            "date                         200 non-null    datetime64[ns]\n",
            " 23  ROSC \n",
            "time                         200 non-null    object        \n",
            " 24  24 hours\n",
            "survival                  200 non-null    object        \n",
            " 25  Survival \n",
            "to discharge             200 non-null    object        \n",
            "dtypes: datetime64[ns](3), int64(4), object(19)\n",
            "memory usage: 40.8+ KB\n"
          ]
        }
      ],
      "source": [
        "# Review schema for the nursing dataset tab\n",
        "df_nd.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRh2LVqTg8B6",
        "outputId": "47ff973f-0c94-4e06-87f9-f3a088fba953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 673 entries, 0 to 672\n",
            "Data columns (total 26 columns):\n",
            " #   Column                             Non-Null Count  Dtype         \n",
            "---  ------                             --------------  -----         \n",
            " 0   MRN                                673 non-null    int64         \n",
            " 1   Gend.                              672 non-null    object        \n",
            " 2   Birth\n",
            "year                         672 non-null    float64       \n",
            " 3   Arrest \n",
            "year                       673 non-null    int64         \n",
            " 4   Age                                672 non-null    float64       \n",
            " 5   CAD                                673 non-null    object        \n",
            " 6   Heart\n",
            "failure                      673 non-null    object        \n",
            " 7   Heart \n",
            "disease                     673 non-null    object        \n",
            " 8   Hyper\n",
            "-tension                     672 non-null    object        \n",
            " 9   COPD                               673 non-null    object        \n",
            " 10  Diabetes                           673 non-null    object        \n",
            " 11  Cancer                             673 non-null    object        \n",
            " 12  Covid\n",
            "at adm                       673 non-null    object        \n",
            " 13  Smoking                            671 non-null    object        \n",
            " 14  Event \n",
            "location                    673 non-null    object        \n",
            " 15  Arrest \n",
            "date                       673 non-null    datetime64[ns]\n",
            " 16  Arrest \n",
            "time                       673 non-null    object        \n",
            " 17  CPR \n",
            "date                          673 non-null    object        \n",
            " 18  CPR \n",
            "time                          673 non-null    object        \n",
            " 19  Defibrillation \n",
            "(time, frequency)  673 non-null    object        \n",
            " 20  Initial cardiac \n",
            "rhythm            672 non-null    object        \n",
            " 21  ROSC \n",
            "(y/n)                        673 non-null    object        \n",
            " 22  ROSC \n",
            "date                         673 non-null    object        \n",
            " 23  ROSC\n",
            "time                          673 non-null    object        \n",
            " 24  24 hours\n",
            "survival                  671 non-null    object        \n",
            " 25  Survival \n",
            "to discharge             672 non-null    object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(2), object(21)\n",
            "memory usage: 136.8+ KB\n"
          ]
        }
      ],
      "source": [
        "df_icu.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM5HOiRlJSpt"
      },
      "source": [
        "### 4. Align Column Names\n",
        "\n",
        "A helper function surfaces naming mismatches between tabs. After normalizing case, whitespace, and punctuation we confirm the schemas align before unioning the records.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr3BwxmxjMtU"
      },
      "outputs": [],
      "source": [
        "def difference():\n",
        "    \"\"\"Report column names that exist in only one of the source DataFrames.\"\"\"\n",
        "    diff_nd = df_nd.columns.difference(df_icu.columns)\n",
        "    diff_icu = df_icu.columns.difference(df_nd.columns)\n",
        "\n",
        "    print(\"Column names in df_nd but not in df_icu:\")\n",
        "    display(diff_nd)\n",
        "\n",
        "    print(\"\\nColumn names in df_icu but not in df_nd:\")\n",
        "    display(diff_icu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3bW9S8bAME_"
      },
      "source": [
        "### 6. CORRECTED: Merge DATE + TIME Before Converting to Datetime\n",
        "\n",
        "**CRITICAL FIX:** We must merge DATE and TIME columns BEFORE converting to datetime.\n",
        "The previous approach converted dates separately, which:\n",
        "- Discards time information\n",
        "- Causes format interpretation issues\n",
        "- Creates negative CPR durations\n",
        "\n",
        "**Correct order:**\n",
        "1. Rename columns (already done)\n",
        "2. **Merge DATE + TIME strings** → Create datetime columns\n",
        "3. Convert merged strings to datetime\n",
        "4. THEN drop separate date/time columns (later)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9496c0c2"
      },
      "outputs": [],
      "source": [
        "# Normalize header casing and remove stray whitespace/newline characters\n",
        "import re\n",
        "\n",
        "df_nd.columns = df_nd.columns.str.lower().str.replace('\\n', ' ').str.strip()\n",
        "df_icu.columns = df_icu.columns.str.lower().str.replace('\\n', ' ').str.strip()\n",
        "\n",
        "# Collapse repeated spaces and strip trailing punctuation to align naming conventions\n",
        "df_nd.columns = (\n",
        "    df_nd.columns\n",
        "        .str.replace(r'\\.+$', '', regex=True)\n",
        "        .str.replace(r'\\s+', ' ', regex=True)\n",
        "        .str.strip()\n",
        ")\n",
        "\n",
        "df_icu.columns = (\n",
        "    df_icu.columns\n",
        "        .str.replace(r'\\.+$', '', regex=True)\n",
        "        .str.replace(r'\\s+', ' ', regex=True)\n",
        "        .str.strip()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7bRB2HRi1Jw"
      },
      "outputs": [],
      "source": [
        "# check the difference again\n",
        "difference()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbebNedIJSpu"
      },
      "source": [
        "### 5. Merge Labeled Sources\n",
        "\n",
        "Tag each record with its origin (`ND` vs `ICU`) so provenance remains traceable after concatenation. Column renaming consolidates verbose headers into analytics-friendly field names while preserving clinical meaning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW4mAs7si4SA"
      },
      "outputs": [],
      "source": [
        "# Harmonize the event location header before concatenation\n",
        "df_nd.rename(columns={'event loc': 'event_location'}, inplace=True)\n",
        "df_icu.rename(columns={'event location': 'event_location'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjvqqVQcjZ-9"
      },
      "outputs": [],
      "source": [
        "difference()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLmfsAuFje7Q"
      },
      "outputs": [],
      "source": [
        "# Preserve provenance while combining both source tabs\n",
        "df_nd[\"origin\"] = \"ND\"\n",
        "df_icu[\"origin\"] = \"ICU\"\n",
        "df = pd.concat([df_nd, df_icu], ignore_index=True)\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPzK5ZzPjwdk"
      },
      "outputs": [],
      "source": [
        "# Rename verbose fields to modeling-friendly aliases while retaining meaning\n",
        "df = df.rename(columns={\n",
        "    'mrn': 'mrn',\n",
        "    'gend': 'gender',\n",
        "    'birth year': 'birth_year',\n",
        "    'arrest year': 'arrest_year',\n",
        "    'age': 'age',\n",
        "    'cad': 'coronary_artery_disease',\n",
        "    'heart failure': 'heart_failure',\n",
        "    'heart disease': 'heart_disease',\n",
        "    'hyper -tension': 'hypertension',\n",
        "    'copd': 'copd',\n",
        "    'diabetes': 'diabetes',\n",
        "    'cancer': 'cancer',\n",
        "    'covid at adm': 'covid_on_admission',\n",
        "    'smoking': 'smoking',\n",
        "    'event_location': 'event_location',\n",
        "    'arrest date': 'arrest_date',\n",
        "    'arrest time': 'arrest_time',\n",
        "    'cpr date': 'cpr_date',\n",
        "    'cpr time': 'cpr_time',\n",
        "    'defibrillation (time, frequency)': 'defibrillation_info',\n",
        "    'initial cardiac rhythm': 'initial_rhythm',\n",
        "    'rosc (y/n)': 'rosc',\n",
        "    'rosc date': 'rosc_date',\n",
        "    'rosc time': 'rosc_time',\n",
        "    '24 hours survival': 'survival_24h',\n",
        "    'survival to discharge': 'survival_to_discharge',\n",
        "    'origin': 'origin'\n",
        "})\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIpAqVeXJSpu"
      },
      "source": [
        "### 6. Create a Working Copy for Feature Standardization\n",
        "\n",
        "Perform exploratory validation and cleaning on a copy of the merged dataset (`df_eda`). This ensures the raw merged frame remains unchanged for auditing while we iteratively standardize each domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xl5f_l-UkteR"
      },
      "outputs": [],
      "source": [
        "# Preserve the merged dataset and work off a mutable copy\n",
        "df_eda = df.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOJicfLBJSpu"
      },
      "source": [
        "#### 6.1 Standardize Demographic Fields\n",
        "\n",
        "Validate the `gender` entries to ensure no missing values remain and that categorical encodings are explicit (`M`, `F`, `U`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c_iwnWelsTW"
      },
      "outputs": [],
      "source": [
        "# Inspect the raw gender distribution and missingness metrics\n",
        "df_eda[\"gender\"].value_counts(dropna=False)\n",
        "df_eda[\"gender\"].unique()\n",
        "df_eda[\"gender\"].isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0N1fdoelwuU"
      },
      "outputs": [],
      "source": [
        "# Impute missing gender values with 'U' (Unknown) for downstream consistency\n",
        "df_eda[\"gender\"] = df_eda[\"gender\"].fillna(\"U\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osWYIpW6JSpw"
      },
      "source": [
        "#### 6.2 Validate Age Consistency\n",
        "\n",
        "Confirm age values remain physiologically plausible by triangulating `age`, `birth_year`, and `arrest_year`. This guards against transcription errors that could bias risk models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Yxc-SJpnfty"
      },
      "outputs": [],
      "source": [
        "# Review descriptive statistics for the age field\n",
        "_df_age_summary = df[\"age\"].describe()\n",
        "_df_age_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKvyRw_qoYbb"
      },
      "outputs": [],
      "source": [
        "# Quantify neonate/infant cases (age ≤ 1 year)\n",
        "(df[\"age\"] <= 1).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJWXsQVGpsSC"
      },
      "outputs": [],
      "source": [
        "# Cross-check reported age against birth and arrest years to flag transcription issues\n",
        "df_eda[\"computed_age\"] = df_eda[\"arrest_year\"] - df_eda[\"birth_year\"]\n",
        "\n",
        "df_eda[\"age_mismatch\"] = (df_eda[\"age\"] - df_eda[\"computed_age\"]).abs() > 1\n",
        "\n",
        "df_eda.loc[df_eda[\"age_mismatch\"], [\"age\", \"birth_year\", \"arrest_year\", \"computed_age\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71BanCmwdoDq"
      },
      "outputs": [],
      "source": [
        "# Remove helper flag after confirming no discrepancies\n",
        "df_eda = df_eda.drop(columns=[\"age_mismatch\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Scp9F-3Wq7CZ"
      },
      "outputs": [],
      "source": [
        "# Validation summary: neonatal records align with arrest and birth years.\n",
        "# The observed minimum age represents true infant cases rather than data entry errors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEMdWwljsDEo"
      },
      "outputs": [],
      "source": [
        "df_eda = df_eda.drop(columns=[\"computed_age\"])  # Remove temporary calculation column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM4AAY_LJSpw"
      },
      "source": [
        "#### 6.3 Standardize Chronic Condition Flags\n",
        "\n",
        "Iteratively validate each comorbidity indicator, harmonizing free-text values and resolving implausible combinations across cardiovascular diagnoses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1jrTCtTsSXh"
      },
      "outputs": [],
      "source": [
        "# Explore raw hypertension responses to scope normalization rules\n",
        "df_eda[\"hypertension\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byZvgfx3sl2S"
      },
      "outputs": [],
      "source": [
        "# Harmonize hypertension values to a consistent Y/N/U encoding\n",
        "df_eda[\"hypertension\"] = df_eda[\"hypertension\"].replace({\"yes\": \"Y\", \"no\": \"N\"})\n",
        "df_eda[\"hypertension\"] = df_eda[\"hypertension\"].fillna(\"U\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Huc7q6jnstD_"
      },
      "outputs": [],
      "source": [
        "# Review diabetes responses before normalization\n",
        "df_eda[\"diabetes\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyHV6Vdkx6kG"
      },
      "outputs": [],
      "source": [
        "# Map free-text diabetes responses to canonical categories\n",
        "df_eda[\"diabetes\"] = df_eda[\"diabetes\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"Yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "    \"No\": \"N\",\n",
        "    \"na\": \"U\"\n",
        "})\n",
        "\n",
        "# Convert genuine NaN values to Unknown\n",
        "df_eda[\"diabetes\"] = df_eda[\"diabetes\"].fillna(\"U\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjvxHPIEyoTN"
      },
      "outputs": [],
      "source": [
        "# Review heart_failure responses before standardization\n",
        "df_eda[\"heart_failure\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj-0P3Dwy76J"
      },
      "outputs": [],
      "source": [
        "# Normalize heart_failure entries to Y/N/U\n",
        "df_eda[\"heart_failure\"] = df_eda[\"heart_failure\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "})\n",
        "\n",
        "df_eda[\"heart_failure\"] = df_eda[\"heart_failure\"].fillna(\"U\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a_NJtR_y_uK"
      },
      "outputs": [],
      "source": [
        "# Review coronary_artery_disease responses before standardization\n",
        "df_eda[\"coronary_artery_disease\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrsYxay9zOEN"
      },
      "outputs": [],
      "source": [
        "# Treat ambiguous 'yn' entries as Unknown to avoid overstating prevalence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5dh6_gCzZLE"
      },
      "outputs": [],
      "source": [
        "df_eda[\"coronary_artery_disease\"] = df_eda[\"coronary_artery_disease\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "    \"yn\": \"U\"   # suspicious → mark as Unknown\n",
        "})\n",
        "\n",
        "df_eda[\"coronary_artery_disease\"] = df_eda[\"coronary_artery_disease\"].fillna(\"U\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdrtBU-CzaII"
      },
      "outputs": [],
      "source": [
        "# Inspect heart_disease responses and align with Y/N conventions\n",
        "df_eda[\"heart_disease\"].value_counts(dropna=False)\n",
        "df_eda[\"heart_disease\"] = df_eda[\"heart_disease\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT0IKofLz5gv"
      },
      "outputs": [],
      "source": [
        "# Identify records where CAD and heart failure are both positive but heart_disease is negative\n",
        "# Clinically, such combinations likely indicate an entry error.\n",
        "df_eda[\"heart_disease_mismatch\"] = (\n",
        "    (df_eda[\"coronary_artery_disease\"] == \"Y\") &\n",
        "    (df_eda[\"heart_failure\"] == \"Y\") &\n",
        "    (df_eda[\"heart_disease\"] == \"N\")\n",
        ")\n",
        "df_eda[\"heart_disease_mismatch\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htj0FRKr0dmf"
      },
      "outputs": [],
      "source": [
        "# Review the conflicting rows to confirm they appear to be data-entry issues rather than true exceptions\n",
        "df_eda[\n",
        "    df_eda[\"heart_disease_mismatch\"]\n",
        "][[\n",
        "    \"age\",\n",
        "    \"gender\",\n",
        "    \"coronary_artery_disease\",\n",
        "    \"heart_failure\",\n",
        "    \"heart_disease\",\n",
        "    \"smoking\",\n",
        "    \"diabetes\",\n",
        "    \"hypertension\",\n",
        "    \"copd\",\n",
        "    \"cancer\",\n",
        "    \"survival_to_discharge\",\n",
        "    \"rosc\",\n",
        "    \"origin\"\n",
        "]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olckJTQJ0p7C"
      },
      "outputs": [],
      "source": [
        "# Override the two conflicting records so that severe cardiac diagnoses remain internally consistent\n",
        "df_eda.loc[\n",
        "    (df_eda[\"coronary_artery_disease\"] == \"Y\") |\n",
        "    (df_eda[\"heart_failure\"] == \"Y\"),\n",
        "    \"heart_disease\"\n",
        "] = \"Y\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E07V9MMi5oh5"
      },
      "outputs": [],
      "source": [
        "# Remove the temporary mismatch indicator after resolving discrepancies\n",
        "df_eda = df_eda.drop(columns=[\"heart_disease_mismatch\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E994BbRr5u7c"
      },
      "outputs": [],
      "source": [
        "# Inspect COPD field for inconsistent encodings\n",
        "df_eda[\"copd\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTevOLVL5_TH"
      },
      "outputs": [],
      "source": [
        "# Standardize COPD responses to uppercase categorical flags\n",
        "df_eda[\"copd\"] = df_eda[\"copd\"].replace({\n",
        "    \"yes\": \"Y\", \"Yes\": \"Y\",\n",
        "    \"no\": \"N\", \"No\": \"N\",\n",
        "    \"na\": \"U\", \"Na\": \"U\", \"NA\": \"U\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6iUffi26Rip"
      },
      "outputs": [],
      "source": [
        "# Inspect cancer responses before recoding\n",
        "df_eda[\"cancer\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84y7WSi56sEG"
      },
      "outputs": [],
      "source": [
        "# Values appear standardized but will still map to ensure case consistency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "selte1sn6laW"
      },
      "outputs": [],
      "source": [
        "# Standardize cancer responses to Y/N\n",
        "df_eda[\"cancer\"] = df_eda[\"cancer\"].replace({\n",
        "    \"yes\": \"Y\", \"Yes\": \"Y\",\n",
        "    \"no\": \"N\", \"No\": \"N\",\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iX35DF06pkC"
      },
      "outputs": [],
      "source": [
        "# Inspect smoking status values to design canonical mapping\n",
        "df_eda[\"smoking\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEV9BtQg6yOY"
      },
      "outputs": [],
      "source": [
        "# Map smoking history to current (`Y`), none (`N`), previous (`P`), or unknown (`U`)\n",
        "df_eda[\"smoking\"] = df_eda[\"smoking\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"Yes\": \"Y\",\n",
        "    \"YES\": \"Y\",\n",
        "\n",
        "    \"no\": \"N\",\n",
        "    \"No\": \"N\",\n",
        "    \"NO\": \"N\",\n",
        "\n",
        "    \"old\": \"Y\",\n",
        "    \"previous\": \"Y\",\n",
        "    \"Previous\": \"Y\",\n",
        "})\n",
        "\n",
        "df_eda[\"smoking\"] = df_eda[\"smoking\"].fillna(\"U\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YyvOIWY66dV"
      },
      "outputs": [],
      "source": [
        "# Validate the distribution after recoding\n",
        "df_eda[\"smoking\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwQtBdlq7H07"
      },
      "outputs": [],
      "source": [
        "# Trim whitespace artifacts that may have prevented replacements from applying\n",
        "df_eda[\"smoking\"] = df_eda[\"smoking\"].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cC8cnRkW70sl"
      },
      "outputs": [],
      "source": [
        "# Re-run mapping after whitespace cleanup to capture remaining variants\n",
        "df_eda[\"smoking\"] = df_eda[\"smoking\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"Yes\": \"Y\",\n",
        "    \"YES\": \"Y\",\n",
        "\n",
        "    \"no\": \"N\",\n",
        "    \"No\": \"N\",\n",
        "    \"NO\": \"N\",\n",
        "    \"na\": \"U\",\n",
        "    \"old\": \"P\",\n",
        "    \"previous\": \"P\",\n",
        "    \"Previous\": \"P\",\n",
        "})\n",
        "\n",
        "df_eda[\"smoking\"] = df_eda[\"smoking\"].fillna(\"U\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiK7qln972xX"
      },
      "outputs": [],
      "source": [
        "# Confirm final smoking distribution and residual unknown volume\n",
        "df_eda[\"smoking\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BmSlaLi81g5"
      },
      "outputs": [],
      "source": [
        "# Note: 12 encounters remain Unknown; retain for now pending clinical clarification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqzfimn8800m"
      },
      "source": [
        "#### 6.4 Admission Infection Status\n",
        "\n",
        "Standardize the COVID-on-admission indicator to the core `Y/N` vocabulary used across the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_1UjHXT74t1"
      },
      "outputs": [],
      "source": [
        "# Review COVID-on-admission responses prior to recoding\n",
        "df_eda[\"covid_on_admission\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzybH4dw889h"
      },
      "outputs": [],
      "source": [
        "# Normalize admission infection status to consistent uppercase codes\n",
        "df_eda[\"covid_on_admission\"] = df_eda[\"covid_on_admission\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7T9g6jAJSp1"
      },
      "source": [
        "#### 6.5 Event Context & Timing Variables\n",
        "\n",
        "Normalize the location codes and validate the sequence of arrest, CPR, and ROSC timestamps to ensure temporal consistency.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyqbHj-c9JFc"
      },
      "outputs": [],
      "source": [
        "# 6.5 Event Context & Timing Variables\n",
        "# Normalize the location codes and validate the sequence of arrest, CPR, and ROSC timestamps to ensure temporal consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SfawsCI9YYK"
      },
      "outputs": [],
      "source": [
        "df_eda[\"event_location\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2nIrOn5JSp1"
      },
      "source": [
        "**Operational definitions for `event_location`:**\n",
        "\n",
        "| Code | Interpretation |\n",
        "| --- | --- |\n",
        "| ICU, ICU2, POST ICU, CCU, CVU, PICU, NICU | Intensive or cardiac critical care units |\n",
        "| MMS, FMS, COVID, COVID UNIT | Medical/surgical wards (grouped as ward care) |\n",
        "| PED, PEDIATRIC | Dedicated pediatric ward |\n",
        "| DSU, DSU (acineto), OPERATING ROOM | Procedural or perioperative spaces |\n",
        "| OBS | Obstetrics ward |\n",
        "| NA | Missing/unknown location |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SgmdKof9aC7"
      },
      "outputs": [],
      "source": [
        "# Reference the glossary above when interpreting event location codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBoUUVzA9lN-"
      },
      "outputs": [],
      "source": [
        "# Normalize casing and remove trailing whitespace before recoding\n",
        "df_eda[\"event_location\"] = df_eda[\"event_location\"].str.lower().str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ1Oy4oi9myb"
      },
      "outputs": [],
      "source": [
        "# Consolidate synonymous unit labels prior to classification\n",
        "df_eda[\"event_location\"] = df_eda[\"event_location\"].replace({\n",
        "    \"icu2\": \"icu\",\n",
        "    \"post icu\": \"post_icu\",\n",
        "    \"covid\": \"covid_unit\",\n",
        "    \"dsu (acineto)\": \"dsu\",\n",
        "    \"ped\": \"pediatric\",\n",
        "    \"picu\": \"pediatric_icu\",\n",
        "    \"nicu\": \"neonatal_icu\",\n",
        "    \"or\": \"operating_room\",\n",
        "    \"obs\": \"obstetrics\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJfekoMs9ozP"
      },
      "outputs": [],
      "source": [
        "# Rename remaining COVID isolation labels to a single value\n",
        "df_eda[\"event_location\"] = df_eda[\"event_location\"].replace({\n",
        "    \"covid_unit\": \"covid_ward\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uYwRpo59r9t"
      },
      "outputs": [],
      "source": [
        "df_eda[\"event_location\"] = df_eda[\"event_location\"].replace(\"na\", \"unknown\")  # Flag missing units explicitly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysaYj8no9uPE"
      },
      "outputs": [],
      "source": [
        "# Verify final location distribution after normalization\n",
        "df_eda[\"event_location\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nbNwnYv9wZq"
      },
      "outputs": [],
      "source": [
        "# Inspect arrest, CPR, and ROSC dates before conversion\n",
        "df_eda[[\"arrest_date\", \"cpr_date\", \"rosc_date\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuQ2FFynCI5r"
      },
      "outputs": [],
      "source": [
        "nan_arrest  = df_eda['arrest_date'].isna().sum()\n",
        "nan_cpr = df_eda['cpr_date'].isna().sum()\n",
        "nan_rosc = df_eda['rosc_date'].isna().sum()\n",
        "\n",
        "nan_arrest, nan_cpr, nan_rosc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUPk0FerYSUD"
      },
      "outputs": [],
      "source": [
        "# make sure they are datetime\n",
        "df_eda[\"arrest_date\"] = pd.to_datetime(df_eda[\"arrest_date\"], errors='coerce', utc=False)\n",
        "df_eda[\"cpr_date\"]    = pd.to_datetime(df_eda[\"cpr_date\"], errors='coerce', utc=False)\n",
        "df_eda[\"rosc_date\"]   = pd.to_datetime(df_eda[\"rosc_date\"], errors='coerce', utc=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jn3vMD4Cels"
      },
      "outputs": [],
      "source": [
        "# With valid datetime types, evaluate whether the event timeline is clinically coherent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlocgpdKpRi_"
      },
      "outputs": [],
      "source": [
        "def calculate_difference_between_dates(df_eda):\n",
        "  df_eda['arrest_to_cpr'] = (df_eda['cpr_date'] - df_eda['arrest_date'])\n",
        "  df_eda['arrest_to_rosc'] = (df_eda['rosc_date'] - df_eda['arrest_date'])\n",
        "  print(df_eda[['arrest_date','cpr_date','rosc_date','arrest_to_cpr','arrest_to_rosc']] \\\n",
        "  .sort_values('arrest_to_rosc', ascending=False))\n",
        "  df_eda.drop(columns=[\"arrest_to_cpr\"], inplace=True, errors=\"ignore\")\n",
        "calculate_difference_between_dates(df_eda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnCvbbOKLVxH"
      },
      "outputs": [],
      "source": [
        "# Identify and correct obvious day/month swaps in ROSC dates\n",
        "cond = (\n",
        "    (df_eda['arrest_date'].dt.month == df_eda['rosc_date'].dt.day) &\n",
        "    (df_eda['arrest_date'].dt.day == df_eda['rosc_date'].dt.month)\n",
        ")\n",
        "\n",
        "df_eda.loc[cond, 'rosc_date'] = df_eda.loc[cond, 'rosc_date'].apply(\n",
        "    lambda x: pd.Timestamp(year=x.year, month=x.day, day=x.month)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBR7VPlz-dA3"
      },
      "outputs": [],
      "source": [
        "# Surface residual records where ROSC precedes arrest or occurs implausibly late\n",
        "# Clinical expectation: ROSC should occur on or after the arrest date and usually within 24 hours.\n",
        "bad_rows = df_eda[\n",
        "    (df_eda['cpr_date'] < df_eda['arrest_date']) |\n",
        "    (df_eda['rosc_date'] < df_eda['arrest_date'])\n",
        "][['arrest_date', 'rosc_date', 'rosc', 'cpr_date']]\n",
        "\n",
        "bad_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnwxqJ8uJnK_"
      },
      "outputs": [],
      "source": [
        "# Manually fix the remaining outliers based on clinical plausibility review\n",
        "# Row 53 shows a swapped day/month pattern; others appear to have ROSC dates entered earlier than arrest.\n",
        "row_53 = df_eda.loc[53, 'rosc_date']\n",
        "swapped = pd.to_datetime(f\"{row_53.year}-{row_53.day:02d}-{row_53.month:02d}\", errors='coerce')\n",
        "if swapped < df_eda.loc[53, 'arrest_date']:\n",
        "    df_eda.loc[53, 'rosc_date'] = df_eda.loc[53, 'arrest_date']\n",
        "else:\n",
        "    df_eda.loc[53, 'rosc_date'] = swapped\n",
        "\n",
        "# Align remaining cases by assuming ROSC occurred on the arrest date when earlier timestamps were entered\n",
        "bad_rows = [166, 190, 258, 789]\n",
        "df_eda.loc[bad_rows, 'rosc_date'] = df_eda.loc[bad_rows, 'arrest_date']\n",
        "\n",
        "# Recalculate deltas to confirm corrections\n",
        "calculate_difference_between_dates(df_eda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fcvn4mfWBtt"
      },
      "outputs": [],
      "source": [
        "# Final manual adjustments identified during spot-check of long arrest-to-ROSC intervals\n",
        "df_eda.loc[730, 'rosc_date'] = pd.to_datetime(\"2023-04-10\")  # Correct transposed day/month\n",
        "\n",
        "df_eda.loc[596, 'rosc_date'] = pd.to_datetime(\"2022-05-09\")  # Align midnight spillover entry\n",
        "calculate_difference_between_dates(df_eda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_s_ZW_oyJSp2"
      },
      "source": [
        "#### 6.6 Normalize Event Times\n",
        "\n",
        "Convert arrest, CPR, and ROSC times into comparable durations (`Timedelta`) so temporal deltas can be computed reliably, even when source formats vary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY6ZKbkaTlsM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BPI2IZmOef5"
      },
      "outputs": [],
      "source": [
        "# Inspect sample arrest times to understand formatting variations\n",
        "df_eda[\"arrest_time\"].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVjN8nbqPR3J"
      },
      "outputs": [],
      "source": [
        "df_eda[\"arrest_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPLCLbDDPPJd"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Convert datetime.time and datetime.datetime objects to strings\n",
        "df_eda['arrest_time'] = df_eda['arrest_time'].apply(\n",
        "    lambda x: x.strftime('%H:%M:%S') if isinstance(x, (datetime.time, datetime.datetime)) else x\n",
        ")\n",
        "\n",
        "# Now, convert the cleaned column to timedelta\n",
        "df_eda[\"arrest_time\"] = pd.to_timedelta(df_eda[\"arrest_time\"], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9cGwndkQ5ZH"
      },
      "outputs": [],
      "source": [
        "df_eda[\"arrest_time\"].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfRLeGWkTN99"
      },
      "outputs": [],
      "source": [
        "df_eda[\"cpr_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY-Na_GUX_5O"
      },
      "outputs": [],
      "source": [
        "df_eda[df_eda[\"cpr_time\"].apply(lambda x: isinstance(x, str))][\"cpr_time\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP5UVuXfYVyZ"
      },
      "outputs": [],
      "source": [
        "df_eda[\"cpr_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFbnpO7sZhk8"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Normalize CPR time strings and mark unusable entries as missing\n",
        "invalid_values = ['na', 'n/a', 'none', 'no cpr', '**', '', 'nan']\n",
        "df_eda.loc[df_eda[\"cpr_time\"].astype(str).str.lower().isin(invalid_values), \"cpr_time\"] = pd.NaT\n",
        "\n",
        "# Define a helper to standardize valid time objects\n",
        "def format_time_safely(x):\n",
        "    if pd.isna(x):\n",
        "        return pd.NaT\n",
        "    if isinstance(x, (datetime.time, datetime.datetime)):\n",
        "        return x.strftime(\"%H:%M:%S\")\n",
        "    return x\n",
        "\n",
        "# Apply normalization and convert to timedeltas\n",
        "df_eda[\"cpr_time\"] = df_eda[\"cpr_time\"].apply(format_time_safely)\n",
        "df_eda[\"cpr_time\"] = pd.to_timedelta(df_eda[\"cpr_time\"], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEsI59GValEd"
      },
      "outputs": [],
      "source": [
        "# Inspect encounters lacking CPR timestamps to understand whether they reflect DNR decisions\n",
        "df_eda[df_eda[\"cpr_time\"].isna()]\n",
        "# Five records have missing CPR times; flag for clinical review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RX34fmavie1W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugYXBtLAbK5k"
      },
      "outputs": [],
      "source": [
        "# Interpretation guide for missing CPR times:\n",
        "# - Survival with missing CPR suggests documentation gaps.\n",
        "# - Death with missing CPR could reflect DNR status or incomplete charting.\n",
        "# - Explicit \"no CPR\" text confirms non-resuscitation orders.\n",
        "# - Missing CPR data + survival=no strengthens the DNR inference.\n",
        "# Follow-up: consult defibrillation details for corroboration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Mza_CxeGNC"
      },
      "outputs": [],
      "source": [
        "df_eda[\"rosc_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LsztB9eemht"
      },
      "outputs": [],
      "source": [
        "df_eda[df_eda[\"rosc_time\"].apply(lambda x: isinstance(x, str))][\"rosc_time\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ob0AyrRe9BY"
      },
      "outputs": [],
      "source": [
        "invalid_values = ['na', 'n/a', 'none', 'no rosc', '**', '', 'nan', 'time na', '??']\n",
        "\n",
        "df_eda.loc[\n",
        "    df_eda[\"rosc_time\"].astype(str).str.lower().isin(invalid_values),\n",
        "    \"rosc_time\"\n",
        "] = pd.NaT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY0M0gQ6fFsR"
      },
      "outputs": [],
      "source": [
        "df_eda[\"rosc_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvV_khElfIhj"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# Define a function to safely convert time objects to strings, handling NaT\n",
        "def format_time_safely_rosc(x):\n",
        "    if pd.isna(x):  # Check if the value is NaT\n",
        "        return pd.NaT\n",
        "    elif isinstance(x, (datetime.time, datetime.datetime)): # Check if it's a time or datetime object\n",
        "        return x.strftime(\"%H:%M:%S\")\n",
        "    else:\n",
        "        return x # Return other types (like already-strings or Timedelta) as is\n",
        "\n",
        "# Apply the safe formatting function\n",
        "df_eda[\"rosc_time\"] = df_eda[\"rosc_time\"].apply(format_time_safely_rosc)\n",
        "\n",
        "# Convert cleaned strings and existing Timedelta/NaT to timedelta safely\n",
        "df_eda[\"rosc_time\"] = pd.to_timedelta(df_eda[\"rosc_time\"], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33UQMYDcl5Bd"
      },
      "outputs": [],
      "source": [
        "# recheck\n",
        "df_eda[\"rosc_time\"].apply(type).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMVsdTvpk00o"
      },
      "outputs": [],
      "source": [
        "# validate event order and find anomalies.\n",
        "df_eda[\"arrest_to_cpr\"] = df_eda[\"cpr_time\"] - df_eda[\"arrest_time\"]\n",
        "df_eda[\"cpr_to_rosc\"] = df_eda[\"rosc_time\"] - df_eda[\"cpr_time\"]\n",
        "df_eda[\"arrest_to_rosc\"] = df_eda[\"rosc_time\"] - df_eda[\"arrest_time\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hslazsCnBDl"
      },
      "outputs": [],
      "source": [
        "# Negative or absurd timings\n",
        "mask_bad = (\n",
        "    (df_eda[\"arrest_to_cpr\"] < pd.Timedelta(0)) |\n",
        "    (df_eda[\"cpr_to_rosc\"] < pd.Timedelta(0))\n",
        ")\n",
        "\n",
        "df_bad = df_eda.loc[mask_bad, [\"mrn\", \"arrest_time\", \"cpr_time\", \"rosc_time\", \"arrest_to_cpr\", \"cpr_to_rosc\", \"arrest_to_rosc\"]]\n",
        "df_bad.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa5uIyr0nDdx"
      },
      "outputs": [],
      "source": [
        "# Combine date and time components to obtain full arrest, CPR, and ROSC timestamps\n",
        "df_eda[\"arrest_dt\"] = df_eda[\"arrest_date\"] + df_eda[\"arrest_time\"]\n",
        "df_eda[\"cpr_dt\"] = df_eda[\"cpr_date\"] + df_eda[\"cpr_time\"]\n",
        "df_eda[\"rosc_dt\"] = df_eda[\"rosc_date\"] + df_eda[\"rosc_time\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYqrbN2qpPYW"
      },
      "outputs": [],
      "source": [
        "df_eda[[\"arrest_dt\",\"cpr_dt\",\"rosc_dt\"]].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs_12w-Eezj_"
      },
      "outputs": [],
      "source": [
        "# Confirm that derived arrest datetimes align with the recorded arrest year\n",
        "df_eda[df_eda[\"arrest_dt\"].dt.year != df_eda[\"arrest_year\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiO3g8_tfOtW"
      },
      "outputs": [],
      "source": [
        "# Drop the intermediate arrest datetime after confirming consistency\n",
        "df_eda.drop(columns=[\"arrest_dt\"], inplace=True, errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l4GONwrpS6_"
      },
      "outputs": [],
      "source": [
        "# Remove helper deltas and redundant date/time columns now that composite timestamps exist\n",
        "df_eda.drop(columns=[\"arrest_to_cpr\", \"cpr_to_rosc\", \"arrest_to_rosc\"], inplace=True, errors=\"ignore\")\n",
        "df_eda.drop(columns=[\"arrest_date\", \"cpr_date\", \"rosc_date\", \"arrest_time\", \"cpr_time\", \"rosc_time\"], inplace=True, errors=\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efkvEd6qJSp5"
      },
      "source": [
        "#### 6.7 Resuscitation Features\n",
        "\n",
        "Standardize initial rhythm labels and engineer defibrillation metrics (shock counts and maximum delivered energy) to support downstream survival modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw-LHewFs1zd"
      },
      "outputs": [],
      "source": [
        "# Review the heterogeneity of initial rhythm entries before cleaning\n",
        "df_eda[\"initial_rhythm\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8i9Ow8stHBW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def clean_rhythm(val):\n",
        "    \"\"\"Collapse free-text rhythm entries into clinically meaningful buckets.\"\"\"\n",
        "    if not isinstance(val, str):\n",
        "        return np.nan\n",
        "    v = val.strip().lower()\n",
        "\n",
        "    if v in [\"asystol\", \"asystole\", \"asystol.\", \"asystol\", \"asysol\", \"aystol\"]:\n",
        "        return \"Asystole\"\n",
        "    if \"asy\" in v:\n",
        "        return \"Asystole\"\n",
        "    if \"pea\" in v:\n",
        "        return \"PEA\"\n",
        "    if \"vf\" in v or \"v-fib\" in v or \"v fib\" in v:\n",
        "        return \"VF\"\n",
        "    if \"vt\" in v or \"v-tach\" in v or \"v tach\" in v:\n",
        "        return \"VT\"\n",
        "    if \"brady\" in v:\n",
        "        return \"Bradycardia\"\n",
        "    if \"sinus\" in v or v == \"sr\":\n",
        "        return \"Sinus/Other\"\n",
        "    if v in [\"af\", \"fa\"]:\n",
        "        return \"AF\"\n",
        "    if v in [\"no\", \"no cpr\", \"na\", \"archive na\", \"**\", \"1x 150j\", \"\"]:\n",
        "        return np.nan\n",
        "    return \"Unknown\"\n",
        "\n",
        "df_eda[\"initial_rhythm\"] = df_eda[\"initial_rhythm\"].apply(clean_rhythm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C7yExUMtPLQ"
      },
      "outputs": [],
      "source": [
        "df_eda[\"initial_rhythm\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orOOsH6EJSp5"
      },
      "source": [
        "The cleaned rhythm categories reveal that asystole dominates the cohort, while shockable rhythms (VF/VT) are rare. A large share of encounters still lack documented rhythm, which should be communicated to clinicians before modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f24A1-u4tQZf"
      },
      "outputs": [],
      "source": [
        "# Refer to the narrative summary above for interpretation of the cleaned rhythm distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zpWunI9tu7M"
      },
      "outputs": [],
      "source": [
        "# Examine defibrillation annotations prior to parsing structured metrics\n",
        "df_eda[\"defibrillation_info\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_kax9Dkv4kx"
      },
      "outputs": [],
      "source": [
        "# Parse phrases like \"1x 100J\" into structured shock_count and max_energy features; default to zero when details are absent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7KEZBdptvYW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_shock_values(val):\n",
        "    \"\"\"Extract shock count and max energy from defibrillation info.\"\"\"\n",
        "    if not isinstance(val, str):\n",
        "        return pd.Series([0, 0])\n",
        "    v = val.strip().lower()\n",
        "    v = re.sub(r'[^0-9xj\\s]', ' ', v)\n",
        "    v = re.sub(r'\\s+', ' ', v).strip()\n",
        "    v = v.replace(' j', 'j').replace('x ', 'x')\n",
        "    matches = re.findall(r'(\\d+)x\\s*([0-9]+)j', v)\n",
        "    if not matches:\n",
        "        return pd.Series([0, 0])\n",
        "    shocks = sum(int(a) for a, _ in matches)\n",
        "    energy = max(int(b) for _, b in matches)\n",
        "    return pd.Series([shocks, energy])\n",
        "\n",
        "# Apply the extractor to derive numeric shock features without discarding any rows\n",
        "df_eda[[\"shock_count\", \"max_energy\"]] = df_eda[\"defibrillation_info\"].apply(extract_shock_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y1zhdOAjuhVV"
      },
      "outputs": [],
      "source": [
        "# Inspect descriptive statistics for engineered defibrillation metrics\n",
        "df_eda[[\"max_energy\", \"shock_count\"]].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_cA1vWhJSp6"
      },
      "source": [
        "#### 6.8 Outcome Harmonization\n",
        "\n",
        "Align ROSC and survival indicators with the same `Y/N/U` semantics and validate cross-field consistency (e.g., ROSC must precede 24-hour survival).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcUX3RpUuil2"
      },
      "outputs": [],
      "source": [
        "# Remove the unstructured defibrillation text column after feature extraction\n",
        "df_eda.drop(columns=[\"defibrillation_info\"], inplace=True, errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kvu3Jbo0fV7"
      },
      "outputs": [],
      "source": [
        "# Review ROSC annotations before normalization\n",
        "df_eda[\"rosc\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZv8NWir4wGk"
      },
      "outputs": [],
      "source": [
        "df_eda[\"rosc\"] = df_eda[\"rosc\"].str.lower().str.strip()\n",
        "\n",
        "df_eda[\"rosc\"] = df_eda[\"rosc\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "    \"na\": \"U\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TusAlkI_5Wzy"
      },
      "outputs": [],
      "source": [
        "df_eda[\"rosc\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bJelISD5Z7l"
      },
      "outputs": [],
      "source": [
        "# Validate that ROSC timestamps exist only when ROSC was achieved\n",
        "invalid_yes = df_eda[(df_eda[\"rosc\"] == \"Y\") & (df_eda[\"rosc_dt\"].isna())]\n",
        "invalid_no = df_eda[(df_eda[\"rosc\"] == \"N\") & (df_eda[\"rosc_dt\"].notna())]\n",
        "\n",
        "print(\"ROSC=Y but no time recorded:\", len(invalid_yes))\n",
        "print(\"ROSC=N but time recorded:\", len(invalid_no))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWQLvg2e7DwP"
      },
      "outputs": [],
      "source": [
        "# Review 24-hour survival outcomes before cleaning\n",
        "df_eda[\"survival_24h\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUP1XRbl7OO5"
      },
      "outputs": [],
      "source": [
        "df_eda[\"survival_24h\"] = df_eda[\"survival_24h\"].str.lower().str.strip()\n",
        "\n",
        "df_eda[\"survival_24h\"] = df_eda[\"survival_24h\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "    \"na\": \"U\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V3cLBkD7Tk9"
      },
      "outputs": [],
      "source": [
        "# Confirm standardized encoding for 24-hour survival\n",
        "df_eda[\"survival_24h\"].value_counts(dropna=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmSBcxFT7UiQ"
      },
      "outputs": [],
      "source": [
        "df_eda[\"survival_24h\"] = df_eda[\"survival_24h\"].replace(\"nan\", \"U\")  # Handle textual NaN artifacts\n",
        "df_eda[\"survival_24h\"] = df_eda[\"survival_24h\"].fillna(\"U\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PezBSvI6-Fpz"
      },
      "outputs": [],
      "source": [
        "# Sanity check: survival at 24 hours requires ROSC to have occurred\n",
        "invalid_24h = df_eda[(df_eda[\"survival_24h\"] == \"Y\") & (df_eda[\"rosc\"] == \"N\")]\n",
        "print(\"Invalid survival_24h (Y but ROSC=N):\", len(invalid_24h))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drxp5T-_Wk3m"
      },
      "outputs": [],
      "source": [
        "# Result: no contradictions detected between ROSC status and 24-hour survival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LadLHxnWXPNl"
      },
      "outputs": [],
      "source": [
        "# Review discharge survival status prior to standardization\n",
        "df_eda[\"survival_to_discharge\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkiRfFSKXPiz"
      },
      "outputs": [],
      "source": [
        "df_eda[\"survival_to_discharge\"] = df_eda[\"survival_to_discharge\"].str.lower().str.strip()\n",
        "df_eda[\"survival_to_discharge\"] = df_eda[\"survival_to_discharge\"].replace(\"nan\", \"U\")\n",
        "df_eda[\"survival_to_discharge\"] = df_eda[\"survival_to_discharge\"].fillna(\"U\")\n",
        "df_eda[\"survival_to_discharge\"] = df_eda[\"survival_to_discharge\"].replace({\n",
        "    \"yes\": \"Y\",\n",
        "    \"no\": \"N\",\n",
        "    \"na\": \"U\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oCRVMJqXcfD"
      },
      "outputs": [],
      "source": [
        "df_eda[\"survival_to_discharge\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNZScaklJSp6"
      },
      "source": [
        "#### 6.9 Infer Encounter Origin\n",
        "\n",
        "Use normalized event locations to backfill missing origin codes (`ND`) while preserving originally captured ICU labels.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtiabhBNJSp6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITbU89k37t3D"
      },
      "outputs": [],
      "source": [
        "# Standardize origin strings and quantify any discrepancies with normalized event locations\n",
        "df_eda[\"origin\"] = df_eda[\"origin\"].astype(str).str.strip().str.upper()\n",
        "df_eda[\"event_location\"] = df_eda[\"event_location\"].astype(str).str.strip().str.upper()\n",
        "\n",
        "icu_origin_not_icu_event = df_eda[\n",
        "    (df_eda[\"origin\"] == \"ICU\") &\n",
        "    (~df_eda[\"event_location\"].str.contains(\"ICU\"))\n",
        "]\n",
        "\n",
        "non_icu_origin_icu_event = df_eda[\n",
        "    (df_eda[\"origin\"] != \"ICU\") &\n",
        "    (df_eda[\"event_location\"].str.contains(\"ICU\"))\n",
        "]\n",
        "\n",
        "print(\"ICU origin but event not in ICU:\", len(icu_origin_not_icu_event))\n",
        "print(\"Non-ICU origin but event in ICU:\", len(non_icu_origin_icu_event))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5aeUTgj8ngt"
      },
      "outputs": [],
      "source": [
        "# Inspect the event location distribution for cases flagged above\n",
        "df_eda['event_location'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlqmKMjh97On"
      },
      "outputs": [],
      "source": [
        "# Derive origin categories based on the standardized event location codes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wriZgXyj9_-x"
      },
      "source": [
        "| event_location                                       | Deduce origin as | Rationale                               |\n",
        "| ---------------------------------------------------- | ---------------- | ---------------------------------------- |\n",
        "| ICU, POST_ICU, CCU, CVU, NEONATAL_ICU, PEDIATRIC_ICU | ICU              | Intensive or coronary-critical units      |\n",
        "| MMS, FMS, COVID_WARD                                 | Ward             | General inpatient or specialty wards      |\n",
        "| PEDIATRIC                                            | Pediatric        | Dedicated pediatric ward                  |\n",
        "| DSU, OPERATING_ROOM, OBSTETRICS                      | OR/Procedure     | Procedural or peri-operative environments |\n",
        "| UNKNOWN                                              | Unknown          | No reliable location signal               |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRoMT9Vi-FTh"
      },
      "outputs": [],
      "source": [
        "def deduce_origin(row):\n",
        "    \"\"\"Infer a cleaner origin label using event location when the source tag is unknown.\"\"\"\n",
        "    origin = str(row[\"origin\"]).strip().upper()\n",
        "    loc = str(row[\"event_location\"]).strip().upper()\n",
        "\n",
        "    if origin not in [\"ND\", \"UNKNOWN\", \"NA\", \"N/A\", \"\"]:\n",
        "        return origin\n",
        "\n",
        "    if loc in [\"ICU\", \"POST_ICU\", \"CCU\", \"CVU\", \"NEONATAL_ICU\", \"PEDIATRIC_ICU\"]:\n",
        "        return \"ICU\"\n",
        "    if loc in [\"MMS\", \"FMS\", \"COVID_WARD\"]:\n",
        "        return \"Ward\"\n",
        "    if loc in [\"PEDIATRIC\"]:\n",
        "        return \"Pediatric\"\n",
        "    if loc in [\"DSU\", \"OPERATING_ROOM\", \"OBSTETRICS\"]:\n",
        "        return \"OR/Procedure\"\n",
        "    return \"Unknown\"\n",
        "\n",
        "df_eda[\"origin\"] = df_eda.apply(deduce_origin, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTAZwIad-U-s"
      },
      "outputs": [],
      "source": [
        "df_eda[\"origin\"].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuZDwa1DJSp7"
      },
      "source": [
        "#### 6.10 Final Quality Checks\n",
        "\n",
        "- Demographic, comorbidity, event-context, timing, resuscitation, and outcome domains now follow unified encoding schemes.\n",
        "- Derived timestamps (`cpr_dt`, `rosc_dt`) and shock metrics (`shock_count`, `max_energy`) replace intermediary helper fields.\n",
        "- Consistency validations (e.g., ROSC vs. survival) return no contradictions, indicating the dataset is ready for modeling or visualization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UIFtd0XJSp7"
      },
      "source": [
        "**Quality control summary**\n",
        "\n",
        "- Demographics (`mrn`, `gender`, `birth_year`, `age`) remain internally consistent.\n",
        "- Comorbidities (CAD, HF, COPD, smoking, etc.) use harmonized categorical codes.\n",
        "- Event context (`origin`, `event_location`) is normalized with inferred values for `ND` records.\n",
        "- Timing fields rely on unified datetime/timedelta representations for arrest, CPR, and ROSC.\n",
        "- Resuscitation metrics (`initial_rhythm`, `shock_count`, `max_energy`) are numerically derived.\n",
        "- Outcomes (`rosc`, `survival_24h`, `survival_to_discharge`) pass cross-field consistency checks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28b4Z9JDYEoC"
      },
      "outputs": [],
      "source": [
        "df_eda.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeV68mrkJSp7"
      },
      "source": [
        "#### 7. Export Clean Dataset\n",
        "\n",
        "Persist the curated dataset to Excel so downstream analysts can consume a single, standardized source.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pqC6HBsYE5p"
      },
      "outputs": [],
      "source": [
        "df_eda.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtgZkA0ta_tE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47f121a1"
      },
      "outputs": [],
      "source": [
        "# Export the cleaned DataFrame to an Excel file\n",
        "df_eda.to_excel(\"ihca_cleaned.xlsx\", index=False)\n",
        "print(\"DataFrame exported to ihca_cleaned.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbREKCxacprf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}